{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dd6129-89e0-4743-aa2d-c6ae4196c6cf",
   "metadata": {},
   "source": [
    "# Deep Learning QA Bot\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n",
    "  \n",
    "\n",
    "## Goal of this Project\n",
    "\n",
    "+ To implement as chat bot that can answer questions basded on a \"story\" given to the bot\n",
    "\n",
    "# There will be three components to this project\n",
    "\n",
    "### Example\n",
    "\n",
    "+ Story: Jane went to the store. Mike ran to the bedroom.\n",
    "\n",
    "+ Question: Is Mike in the store?\n",
    "\n",
    "+ Goal - Bot to answer: No\n",
    "\n",
    "\n",
    "\n",
    "# How the QA Bot Network Works\n",
    "\n",
    "+ Model takes a discrete set of inputs that are to be stored in the memory\n",
    "+ It will take a corresponding question and output an answer\n",
    "+ Each of the inputs, questions and answers contain symbols coming from a dictionary with vocabulary words\n",
    "+ Model then write all of the text to the memory up to a fixed buffer size, and then finds a continuous representation for the text and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197fc869-245b-47da-b9ae-3163a42675c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd94f590-3e9f-46a4-ba6e-12ae21009da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickling train text data and storing it into a variable\n",
    "\n",
    "with open(\"train_qa.txt\", \"rb\") as fp:    # Unpickling\n",
    "    train_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f664d0a-1c20-468e-b6eb-66db055064a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickling test text data and storing it into a variable\n",
    "\n",
    "with open(\"test_qa.txt\", \"rb\") as fp:    # Unpickling\n",
    "    test_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b0903-4db7-4e2c-b64f-fff9f02d0d71",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67922ce-b977-4e74-9b94-9511a9b6d5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the type function to understand the type of object the test data is\n",
    "\n",
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1358b925-9b6c-4d87-b263-dd27d253bd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the type function to understand the type of object the training data is\n",
    "\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dae8c03-a2c0-46be-a700-ef3ca472b262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now looking at the length of the test data\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4f0df8-ae58-4aaf-be1c-2aa4508f8157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now looking at the length of the train data\n",
    "\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2a163e9-fcaa-4a62-8e3a-5bb7f1849e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the first tuple in the training data\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11c23e91-582c-455b-9c47-59b9fd8fb2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating the first tuple into a sentence\n",
    "\n",
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e07b4c75-392a-4abb-96f6-19bd56705ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating the question in the first tuple\n",
    "\n",
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3bccfa5-5b22-4df7-ba79-9523b8b069e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the answer in the first tuple\n",
    "\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de16e402-9f14-4c4d-a2cd-c5db08362715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set that holds the vocab words\n",
    "# stores unique values\n",
    "\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "819f4ff1-0136-499d-9dc1-8be7ddca0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new variable that contrains both datasets and is a big list\n",
    "\n",
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac0270f-6cdd-4de6-9cb4-0be2e4fa1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a for loop to add all distinct words for the story, the question and the answer\n",
    "\n",
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story)) # union will look for all distinct values between the two sets / continuously adding new distinct words while keeping current list in consideration\n",
    "    vocab = vocab.union(set(question)) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01890c29-cbba-4cb1-b6fd-8888adb32644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding yes and no to the vocabulary\n",
    "\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5444cbaf-4636-41d5-a9c9-4c30316bcef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the set of all possible vocab words\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cbb662d-8dd5-4e06-80ae-e208c9266301",
   "metadata": {},
   "outputs": [],
   "source": [
    " #we add an extra space to hold a 0 for Keras's pad_sequences\n",
    "\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa31c448-0c65-4ab4-9b3f-ec393ee14257",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d950ca-0b71-48ec-89f6-fe8bd64cb62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba94c324-334a-459b-8a1d-252aa9a93435",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15d89a50-af15-4907-8622-88b7d436e0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e22b690-7935-4fe1-b2a8-522e17447bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e14f949e-47b3-4216-a38b-b02b8606adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fef75b9-795c-4777-81eb-74371bb90591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "328ddc85-9cf6-4133-aa1d-1be729ece4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a25e49a9-553d-4c75-a7d6-fd5d2648ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kitchen': 1,\n",
       " 'to': 2,\n",
       " 'went': 3,\n",
       " 'daniel': 4,\n",
       " 'dropped': 5,\n",
       " 'got': 6,\n",
       " 'is': 7,\n",
       " 'left': 8,\n",
       " 'sandra': 9,\n",
       " '?': 10,\n",
       " 'journeyed': 11,\n",
       " 'there': 12,\n",
       " '.': 13,\n",
       " 'bedroom': 14,\n",
       " 'office': 15,\n",
       " 'milk': 16,\n",
       " 'took': 17,\n",
       " 'john': 18,\n",
       " 'picked': 19,\n",
       " 'hallway': 20,\n",
       " 'moved': 21,\n",
       " 'apple': 22,\n",
       " 'mary': 23,\n",
       " 'grabbed': 24,\n",
       " 'the': 25,\n",
       " 'in': 26,\n",
       " 'garden': 27,\n",
       " 'put': 28,\n",
       " 'back': 29,\n",
       " 'football': 30,\n",
       " 'down': 31,\n",
       " 'travelled': 32,\n",
       " 'yes': 33,\n",
       " 'bathroom': 34,\n",
       " 'up': 35,\n",
       " 'no': 36,\n",
       " 'discarded': 37}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07e2f0f6-ecdf-4038-833e-2de21e760a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78244811-fbc0-4571-b548-e5e9e9aa87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e4c8a89-9102-4338-b391-7cd933ebf5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7cd398d-d19e-4190-a269-6792c38188be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdd2bf2c-2364-4d37-af8c-679aa4c0aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e6ff7a2-f591-44c5-9b8c-218e06ecbe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7136d430-99c9-4cd1-87ff-c38d204e9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "839f7ed4-a7c6-413f-bb67-c615d2445458",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d248f94a-297b-4474-8aa2-f1b1a24f2897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 25, 14, 13],\n",
       "       [ 0,  0,  0, ..., 25, 27, 13],\n",
       "       [ 0,  0,  0, ..., 25, 27, 13],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 25, 22, 13],\n",
       "       [ 0,  0,  0, ..., 25, 27, 13],\n",
       "       [ 0,  0,  0, ..., 22, 12, 13]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9f3fe79-ed7a-4352-a45c-6eb51ceb4f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 18, 26, 25,  1, 10],\n",
       "       [ 7, 18, 26, 25,  1, 10],\n",
       "       [ 7, 18, 26, 25, 27, 10],\n",
       "       ...,\n",
       "       [ 7, 23, 26, 25, 14, 10],\n",
       "       [ 7,  9, 26, 25, 27, 10],\n",
       "       [ 7, 23, 26, 25, 27, 10]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47f41511-5ed3-4d8b-890a-018ed3282413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f8c9d8e-dbbb-4edf-985e-ad1c2b5db5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       497.,   0.,   0., 503.,   0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8305333c-d0c3-4c59-8df4-d1d068dd410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e070d513-b1c3-4d55-9940-1b0d92e94812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88830341-71a9-428f-869c-82623d9af93a",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85462481-30d5-4904-bd59-13876378b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31995c65-cb5c-4651-b8c5-9fd7d2ff698d",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84de22b5-c94b-4d2d-af41-69a562ff11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e10ab0-193d-4585-9917-fdb924bc62e1",
   "metadata": {},
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fcd82-8795-4af8-bb0c-f35eab9a6eb9",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01c46900-7c39-49e2-94f2-2a63a775bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c81d33-0450-468b-b66c-facaa3a741f7",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d49c534-5b6d-42de-a43e-4695049d1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5929bd-f736-449b-b74d-52a6fb9b85d2",
   "metadata": {},
   "source": [
    "## Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfc6fae6-f70d-42a0-8cbc-474a0a020a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288530ac-e145-40d7-90f2-875ab4558bc3",
   "metadata": {},
   "source": [
    "## Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8bcc616-f6fd-4568-b1b6-894a26446287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b82fa-46d9-4855-9d23-e1bed125a2e0",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93c727bb-30a5-457a-aa0d-2b2721fd10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17371305-2dc2-4e6a-a893-fd48241d761e",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "052670a9-0873-4013-b9a8-3c737a224b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6a8b56-0795-4653-84ca-65f78bc0bb71",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ad1a97c-dad4-4b9d-b4cf-5e5d63b8b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "791906e1-f5b7-4292-95f4-41b83feb1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b42fec81-2e5a-49ad-b4a3-212948aad96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1552dea-8f85-477e-a618-af0ebe47c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03cf8b88-933c-4d0d-a1b1-19edc17a0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c01d839-7fd3-4647-b229-32c3e4fb5b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdf64ffb-7ac0-47ff-aaea-a01db032b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 6s 7ms/step - loss: 0.8695 - accuracy: 0.4942 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7032 - accuracy: 0.5013 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6957 - accuracy: 0.5028 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6943 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.5060 - val_loss: 0.6982 - val_accuracy: 0.5030\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.4967 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6942 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.4950\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6940 - accuracy: 0.5069 - val_loss: 0.6954 - val_accuracy: 0.4860\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6930 - accuracy: 0.5053 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6906 - accuracy: 0.5307 - val_loss: 0.6920 - val_accuracy: 0.5090\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6764 - accuracy: 0.5656 - val_loss: 0.6689 - val_accuracy: 0.5410\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6468 - accuracy: 0.6241 - val_loss: 0.6293 - val_accuracy: 0.6560\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6270 - accuracy: 0.6538 - val_loss: 0.6091 - val_accuracy: 0.6610\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6080 - accuracy: 0.6785 - val_loss: 0.6028 - val_accuracy: 0.6820\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5989 - accuracy: 0.6820 - val_loss: 0.5734 - val_accuracy: 0.7090\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5807 - accuracy: 0.7054 - val_loss: 0.5509 - val_accuracy: 0.7410\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5571 - accuracy: 0.7247 - val_loss: 0.5144 - val_accuracy: 0.7570\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5281 - accuracy: 0.7458 - val_loss: 0.4841 - val_accuracy: 0.7750\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5054 - accuracy: 0.7630 - val_loss: 0.4811 - val_accuracy: 0.7840\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4882 - accuracy: 0.7719 - val_loss: 0.4539 - val_accuracy: 0.7820\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4768 - accuracy: 0.7816 - val_loss: 0.4435 - val_accuracy: 0.7820\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4533 - accuracy: 0.7981 - val_loss: 0.4299 - val_accuracy: 0.7910\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4397 - accuracy: 0.8026 - val_loss: 0.4429 - val_accuracy: 0.7740\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4192 - accuracy: 0.8052 - val_loss: 0.4169 - val_accuracy: 0.8030\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4103 - accuracy: 0.8133 - val_loss: 0.4002 - val_accuracy: 0.8030\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3953 - accuracy: 0.8218 - val_loss: 0.4013 - val_accuracy: 0.8060\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3897 - accuracy: 0.8233 - val_loss: 0.3893 - val_accuracy: 0.8070\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3788 - accuracy: 0.8270 - val_loss: 0.3930 - val_accuracy: 0.8040\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3614 - accuracy: 0.8384 - val_loss: 0.3827 - val_accuracy: 0.8190\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.8464 - val_loss: 0.4287 - val_accuracy: 0.8040\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3497 - accuracy: 0.8470 - val_loss: 0.3775 - val_accuracy: 0.8180\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3432 - accuracy: 0.8485 - val_loss: 0.3577 - val_accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3310 - accuracy: 0.8559 - val_loss: 0.3539 - val_accuracy: 0.8320\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3275 - accuracy: 0.8595 - val_loss: 0.3470 - val_accuracy: 0.8330\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3185 - accuracy: 0.8606 - val_loss: 0.3396 - val_accuracy: 0.8370\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3182 - accuracy: 0.8585 - val_loss: 0.3427 - val_accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3112 - accuracy: 0.8629 - val_loss: 0.3476 - val_accuracy: 0.8380\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3053 - accuracy: 0.8663 - val_loss: 0.3465 - val_accuracy: 0.8390\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3089 - accuracy: 0.8659 - val_loss: 0.3513 - val_accuracy: 0.8380\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3073 - accuracy: 0.8667 - val_loss: 0.3411 - val_accuracy: 0.8330\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3052 - accuracy: 0.8653 - val_loss: 0.3494 - val_accuracy: 0.8320\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3004 - accuracy: 0.8660 - val_loss: 0.3436 - val_accuracy: 0.8360\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3021 - accuracy: 0.8675 - val_loss: 0.3443 - val_accuracy: 0.8400\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3019 - accuracy: 0.8680 - val_loss: 0.3490 - val_accuracy: 0.8420\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2961 - accuracy: 0.8690 - val_loss: 0.3491 - val_accuracy: 0.8380\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2951 - accuracy: 0.8695 - val_loss: 0.3326 - val_accuracy: 0.8420\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2956 - accuracy: 0.8695 - val_loss: 0.3530 - val_accuracy: 0.8290\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2968 - accuracy: 0.8703 - val_loss: 0.3541 - val_accuracy: 0.8370\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2961 - accuracy: 0.8700 - val_loss: 0.3432 - val_accuracy: 0.8330\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2929 - accuracy: 0.8728 - val_loss: 0.3495 - val_accuracy: 0.8370\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2930 - accuracy: 0.8699 - val_loss: 0.3512 - val_accuracy: 0.8330\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2871 - accuracy: 0.8740 - val_loss: 0.3755 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2937 - accuracy: 0.8720 - val_loss: 0.3878 - val_accuracy: 0.8290\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2882 - accuracy: 0.8725 - val_loss: 0.3472 - val_accuracy: 0.8330\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2895 - accuracy: 0.8720 - val_loss: 0.3619 - val_accuracy: 0.8370\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2897 - accuracy: 0.8738 - val_loss: 0.3453 - val_accuracy: 0.8380\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2906 - accuracy: 0.8730 - val_loss: 0.3705 - val_accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2867 - accuracy: 0.8761 - val_loss: 0.3726 - val_accuracy: 0.8390\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2837 - accuracy: 0.8735 - val_loss: 0.3967 - val_accuracy: 0.8230\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2790 - accuracy: 0.8793 - val_loss: 0.3754 - val_accuracy: 0.8270\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2806 - accuracy: 0.8765 - val_loss: 0.3557 - val_accuracy: 0.8290\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2800 - accuracy: 0.8775 - val_loss: 0.3731 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2796 - accuracy: 0.8784 - val_loss: 0.3853 - val_accuracy: 0.8380\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2734 - accuracy: 0.8808 - val_loss: 0.3716 - val_accuracy: 0.8310\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2736 - accuracy: 0.8770 - val_loss: 0.3678 - val_accuracy: 0.8320\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2796 - accuracy: 0.8813 - val_loss: 0.3740 - val_accuracy: 0.8320\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2757 - accuracy: 0.8804 - val_loss: 0.3708 - val_accuracy: 0.8320\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2788 - accuracy: 0.8773 - val_loss: 0.3625 - val_accuracy: 0.8360\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2789 - accuracy: 0.8807 - val_loss: 0.3770 - val_accuracy: 0.8350\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2748 - accuracy: 0.8815 - val_loss: 0.3692 - val_accuracy: 0.8390\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2772 - accuracy: 0.8801 - val_loss: 0.3562 - val_accuracy: 0.8440\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2720 - accuracy: 0.8821 - val_loss: 0.3662 - val_accuracy: 0.8390\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2627 - accuracy: 0.8863 - val_loss: 0.3832 - val_accuracy: 0.8340\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2698 - accuracy: 0.8831 - val_loss: 0.3818 - val_accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2732 - accuracy: 0.8799 - val_loss: 0.3610 - val_accuracy: 0.8310\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2682 - accuracy: 0.8862 - val_loss: 0.3949 - val_accuracy: 0.8350\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2617 - accuracy: 0.8891 - val_loss: 0.3967 - val_accuracy: 0.8310\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2620 - accuracy: 0.8872 - val_loss: 0.4048 - val_accuracy: 0.8320\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2614 - accuracy: 0.8842 - val_loss: 0.3822 - val_accuracy: 0.8380\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2720 - accuracy: 0.8843 - val_loss: 0.3686 - val_accuracy: 0.8350\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2608 - accuracy: 0.8882 - val_loss: 0.4030 - val_accuracy: 0.8300\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2634 - accuracy: 0.8876 - val_loss: 0.3881 - val_accuracy: 0.8340\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2654 - accuracy: 0.8876 - val_loss: 0.3885 - val_accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2636 - accuracy: 0.8896 - val_loss: 0.4342 - val_accuracy: 0.8310\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2557 - accuracy: 0.8878 - val_loss: 0.3939 - val_accuracy: 0.8340\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2533 - accuracy: 0.8934 - val_loss: 0.4090 - val_accuracy: 0.8320\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2510 - accuracy: 0.8913 - val_loss: 0.4104 - val_accuracy: 0.8300\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2573 - accuracy: 0.8863 - val_loss: 0.4140 - val_accuracy: 0.8270\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2582 - accuracy: 0.8890 - val_loss: 0.4200 - val_accuracy: 0.8320\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2565 - accuracy: 0.8887 - val_loss: 0.3928 - val_accuracy: 0.8340\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2514 - accuracy: 0.8907 - val_loss: 0.4018 - val_accuracy: 0.8310\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2516 - accuracy: 0.8923 - val_loss: 0.4064 - val_accuracy: 0.8350\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2562 - accuracy: 0.8937 - val_loss: 0.4096 - val_accuracy: 0.8350\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2503 - accuracy: 0.8941 - val_loss: 0.4180 - val_accuracy: 0.8330\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2495 - accuracy: 0.8961 - val_loss: 0.3910 - val_accuracy: 0.8280\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2421 - accuracy: 0.8934 - val_loss: 0.4132 - val_accuracy: 0.8290\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2476 - accuracy: 0.8941 - val_loss: 0.4364 - val_accuracy: 0.8300\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2493 - accuracy: 0.8934 - val_loss: 0.4083 - val_accuracy: 0.8310\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2400 - accuracy: 0.8981 - val_loss: 0.4243 - val_accuracy: 0.8220\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=100,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f5e9da1-a5c3-4c6a-8a5f-972dc1951fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaco\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "### Saving the model\n",
    "\n",
    "file = 'chatbot.h5'\n",
    "model.save(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372b8f5-f55e-4c56-a0f2-4292ca24f67e",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "#### Plotting out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2809a814-067c-448b-9169-8f6015e175e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff5c06-717e-4b12-be9e-a797cd531815",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91aa7875-672e-43a4-9e67-66f564479528",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(file)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81ee3d52-2648-4ce0-890d-3f464099be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b9d099b-ea2e-4504-b618-b23054255baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "291df318-4468-4791-9d63-3cc9d66fb4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4866a07-e6b6-49f3-880b-3e6e93462c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50e09f57-8c8b-443b-9a1c-7f45fd146a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99999917\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd512d-53a4-4cc0-b220-8d0482849d5a",
   "metadata": {},
   "source": [
    "## Writing Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18dc3aa2-8c4c-4855-af6d-12643089fc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a19dc3d-8248-4396-aae5-3e41aa39c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62555a08-2551-465e-9401-7b0a9a0d2f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b75e71ae-98b3-423b-828d-9e1057172d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a17eedfb-14fc-40c9-9120-f67bae018706",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f577eed1-d6fd-4990-8814-a1ae9fada60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a9ff72d-bb19-4cd9-aeab-8b8a2b0c4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99525106\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e56491-8ee5-438f-b444-2748e78f0154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046c4c-d6f0-4a3b-a3d4-22c273194109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85928bd-9076-41d6-998d-bef98130d594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
